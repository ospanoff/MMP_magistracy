{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Лабораторная работа №1 (курс \"Математические методы анализа текстов\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Тема: Определение частей речи и выделение именованных сущностей.\n",
    "\n",
    "\n",
    "**Выдана**:   25 февраля 2017\n",
    "\n",
    "**Дедлайн**:   <font color='red'>9:00 утра 13 марта 2017</font>\n",
    "\n",
    "**Среда выполнения**: Jupyter Notebook (Python 2.7)\n",
    "\n",
    "#### Правила:\n",
    "\n",
    "Результат выполнения задания - отчет в формате Jupyter Notebook с кодом и выводами. В ходе выполнения задания требуется реализовать все необходимые алгоритмы, провести эксперименты и ответить на поставленные вопросы. Дополнительные выводы приветствуются. Чем меньше кода и больше комментариев - тем лучше.\n",
    "\n",
    "Все ячейки должны быть \"выполненными\", при этом результат должен воспроизвдиться при проверке (на Python 2.7). Если какой-то код не был запущен или отрабатывает с ошибками, то пункт не засчитывается. Задание, сданное после дедлайна, _не принимается_. Совсем.\n",
    "\n",
    "\n",
    "Задание выполняется самостоятельно. Вы можете обсуждать идеи, объяснять друг другу материал, но не можете обмениваться частями своего кода. Если какие-то студенты будут уличены в списывании, все они автоматически получат за эту работу 0 баллов, а также предвзято негативное отношение семинаристов в будущем. Если вы нашли в Интернете какой-то код, который собираетесь заимствовать, обязательно укажите это в задании: вполне вероятно, что вы не единственный, кто найдёт и использует эту информацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Постановка задачи:\n",
    "\n",
    "В данной лабораторной работе вам предстоит:\n",
    "\n",
    "- обучить скрытую марковскую модель на размеченных данных и реализовать алгоритм Витерби для задачи POS-теггинга (определение частей речи слов в тексте)\n",
    "\n",
    "- научиться использовать ряд POS-теггеров из библиотеки NLTK и сравнить качество их работы\n",
    "\n",
    "- придумать различные признаки для CRF и использовать их в реализации CRF из пакета CRFsuite для решения задачи NER (выделение именованных сущностей в тексте)\n",
    "\n",
    "- использовать готовое решение для решения задачи NER и сравнить качество"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Комментарии и советы:\n",
    "\n",
    "1. Для выполнения потребуются модули Python numpy, nltk, pycrfsuite (для импорта последнего нужно установить пакет python-crfsuite).\n",
    "\n",
    "2. Все необходимые для выполнения задания данные либо приложены, либо могут быть скачаны с помощью nltk.download().\n",
    "\n",
    "3. Посмотреть параметры конструктора и других методов классов можно набрав и выполнив в ячейке с кодом '?full_method_name'.\n",
    "\n",
    "4. В коде Stanford NER tagger, возможно, присутствует ошибка. Для её устранения в файле /usr/local/lib/python2.7/site-packages/nltk/tag/api.py (или его аналоге в Windows) замените строку с номером 66 на следующую: tagged_sents = self.tag_sents([untag(sent) for sent in gold])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. Определение частей речи (POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Мы будем решать задачу определения частей речи (POS-теггинга) с помощью скрытой марковской модели (HMM). Формула совместной плотности наблюдаемых и скрытых переменных задается как\n",
    "\n",
    "$$ p(X, T) = p(T) p(X|T) = p(t_1)  \\prod_{i=2}^N p(t_i|t_{i-1}) \\prod_{i=1}^N p(x_i|t_i)$$\n",
    "\n",
    "В данном случае:\n",
    "\n",
    "- наблюдаемые переменные $X$ - это слова корпуса;\n",
    "\n",
    "- скрытые переменные $T$ - это POS-теги."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 1.1. Обучение HMM на размеченных данных\n",
    "\n",
    "Требуется построить скрытую марковскую модель и настроить все ее параметры с помощью оценок максимального правдоподобия по размеченным данным (последовательности пар слово+тег):\n",
    "\n",
    "- Вероятности переходов между скрытыми состояниями $p(t_i | t_{i - 1})$ посчитайте на основе частот биграмм POS-тегов.\n",
    "\n",
    "- Вероятности эмиссий наблюдаемых состояний $p(x_i | t_i)$ посчитайте на основе частот \"POS-тег - слово\".\n",
    "\n",
    "- Обратите внимание на проблему разреженности счетчиков и сделаейте все вероятности сглаженными по Лапласу (add-one smoothing).\n",
    "\n",
    "- Распределение вероятностей начальных состояний $p(t_1)$ задайте равномерным.\n",
    "\n",
    "Обратите внимание, что так как мы используем размеченные данные, то у нас нет необходимости в оценивании апостериорных вероятностей на скрытые переменные с помощью алгоритма forward-backword и использовании EM-алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    MAX_TAGS = 50\n",
    "    MAX_WORDS = 50000\n",
    "    \n",
    "    def __init__(self, lower=True):\n",
    "        self.lower = lower\n",
    "    \n",
    "    def fit(self, sentences):\n",
    "        word_tag = np.ones((self.MAX_WORDS, self.MAX_TAGS))\n",
    "        tag_tag = np.ones((self.MAX_TAGS, self.MAX_TAGS))\n",
    "        words_dict = dict()\n",
    "        tags_dict = dict()\n",
    "        \n",
    "        tag_i, word_i = 0, 0\n",
    "        for sentence in sentences:\n",
    "            prev_tag = None\n",
    "            for word, tag in sentence:\n",
    "                if self.lower:\n",
    "                    word = word.lower()\n",
    "                \n",
    "                if word not in words_dict:\n",
    "                    words_dict[word] = word_i\n",
    "                    word_i += 1\n",
    "                    \n",
    "                if tag not in tags_dict:\n",
    "                    tags_dict[tag] = tag_i\n",
    "                    tag_i += 1\n",
    "                    \n",
    "                word_tag[words_dict[word], tags_dict[tag]] += 1\n",
    "                if prev_tag is not None:\n",
    "                    tag_tag[tags_dict[prev_tag], tags_dict[tag]] += 1\n",
    "                    \n",
    "                prev_tag = tag\n",
    "        \n",
    "        self.word_tag = np.copy(word_tag[:word_i, :tag_i])\n",
    "        self.tag_tag = np.copy(tag_tag[:tag_i, :tag_i])\n",
    "        self.words_dict = words_dict\n",
    "        self.tags_dict = tags_dict\n",
    "        \n",
    "        del word_tag\n",
    "        del tag_tag\n",
    "        \n",
    "        self.word_tag_prob = self.word_tag / self.word_tag.sum(axis=0)\n",
    "        self.tag_tag_prob = self.tag_tag / self.tag_tag.sum(axis=1)[:, np.newaxis]\n",
    "        self.tags_dist = np.ones(len(self.tags_dict)) / len(self.tags_dict)\n",
    "        \n",
    "    def predict(self, sentence):\n",
    "        delta = np.zeros((len(self.tags_dict), len(sentence)))\n",
    "        s = np.zeros((len(self.tags_dict), len(sentence) - 1), dtype=np.int)\n",
    "        \n",
    "        word = sentence[0].lower() if self.lower else sentence[0]\n",
    "        delta[:, 0] = np.log(self.tags_dist) + np.log(self.word_tag_prob[self.words_dict[word]])\n",
    "        tt_log = np.log(self.tag_tag_prob)\n",
    "        for i, word in enumerate(sentence[1:]):\n",
    "            if self.lower:\n",
    "                word = word.lower()\n",
    "                \n",
    "            tmp = delta[:, i, np.newaxis] + tt_log +\\\n",
    "                  np.log(self.word_tag_prob[self.words_dict[word]])\n",
    "                    \n",
    "            s[:, i] = np.argmax(tmp, axis=0)\n",
    "            delta[:, i + 1] = np.max(tmp, axis=0)\n",
    "            \n",
    "        tag_by_indx = sorted(self.tags_dict, key=self.tags_dict.get)\n",
    "        \n",
    "        tag_indx = np.argmax(delta[:, -1])\n",
    "        prediction = [tag_by_indx[tag_indx]]\n",
    "        for i in range(s.shape[1] - 1, -1, -1):\n",
    "            tag_indx = s[tag_indx, i]\n",
    "            prediction += [tag_by_indx[tag_indx]]\n",
    "            \n",
    "        return prediction[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Загрузите brown корпус с универсальной системой тегирования. Для этого вам понадобятся ресурсы brown и universal_tagset из nltk.download().  В этой системе содержатся следующие теги:\n",
    "\n",
    "- ADJ - adjective (new, good, high, ...)\n",
    "- ADP - adposition\t(on, of, at, ...)\n",
    "- ADV - adverb\t(really, already, still, ...)\n",
    "- CONJ\t- conjunction\t(and, or, but, ...)\n",
    "- DET - determiner, article\t(the, a, some, ...)\n",
    "- NOUN\t- noun\t(year, home, costs, ...)\n",
    "- NUM - numeral\t(twenty-four, fourth, 1991, ...)\n",
    "- PRT -\tparticle (at, on, out, ...)\n",
    "- PRON - pronoun (he, their, her, ...)\n",
    "- VERB - verb (is, say, told, ...)\n",
    "- .\t- punctuation marks\t(. , ;)\n",
    "- X\t- other\t(ersatz, esprit, dunno, ...)\n",
    "\n",
    "Обратите внимание, что тегсеты в корпусах текстов и в различных теггерах могут быть разными. Проверять это можно, глядя на сами теги, а симптом - подозрительно низкое качество теггирования. В таких случаях рекомендуется всё приводить сперва к универсальному тегсету, а потом уже мерять качество. Полезной может оказаться эта ссылка http://www.nltk.org/_modules/nltk/tag/mapping.html\n",
    "\n",
    "Проанализируйте данные, с которыми Вы работаете. В частности, ответьте на вопросы:\n",
    "- Каков общий объем датасета, формат?\n",
    "- Приведены ли слова к нижнему регистру? Чем  это нам может в дальнейшем помешать?\n",
    "- Как распределены слова в корпусе?  Как распределены теги в корпусе? Подсчитайте частоты и отобразите любым удобным для Вас способом. Проинтерпретируйте полученные результаты.\n",
    "\n",
    "Задем сделайте случайное разбиение выборки на обучение и контроль в отношении 9:1 и обучите скрытую марковскую модель из предыдущего пункта. Если впоследствии обучение моделей будет занимать слишком много времени, работайте с подвыборкой, например, только текстами определенных категорий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "brown_tagged_sents = brown.tagged_sents(tagset=\"universal\")\n",
    "\n",
    "# you code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(brown_tagged_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 1.2 Алгоритм Витерби для применения модели\n",
    "\n",
    "Чтобы использовать обученную модель для определения частей речи на новых данных, необходимо реализовать алгоритм Витерби. Это алгоритм динамиеского программирования, с помощью которого мы будем находить наиболее вероятную последовательность скрытых состояний модели для фиксированной последовательности слов:\n",
    "\n",
    "$$ \\hat{T} = \\arg \\max_{T} p(T|X) = \\arg \\max_{T} p(X, T) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Определим функцию, определяющую максимальную вероятность последовательности, заканчивающейся на $i$-ой позиции в состоянии $k$:\n",
    "\n",
    "$$\\delta(k, i) = \\max_{t_1, \\dots t_{i-1}} p(x_1, \\dots x_i, t_1, \\dots t_i=k)$$\n",
    "\n",
    "Тогда $\\max_{k} \\delta(k, N)$ - максимальная вероятность всей последовательности. А состояния, на которых эта вероятность достигается - ответ задачи.\n",
    "\n",
    "Алгоритм Витерби заключается в последовательном пересчете функции $\\delta(k, i)$ по формуле:\n",
    "\n",
    "$$\\delta(k, i) = \\max_{m} \\delta(m, i-1) p(t_i = k|t_{i-1} = m) p(x_i|t_i=k) $$\n",
    "\n",
    "Аналогично пересчитывается функция, определяющая, на каком состоянии этот максимум достигается:\n",
    "\n",
    "$$s(k, i) = \\arg \\max_{m} \\delta(m, i-1) p(t_i = k|t_{i-1} = m) p(x_i|t_i=k) $$\n",
    "\n",
    "\n",
    "На практике это означает заполнение двумерных массивов размерности: (длина последовательности) $\\times$ (количество возможных состояний). Когда массивы заполнены, $\\arg \\max_{k} \\delta(k, N)$ говорит о последнем состоянии. Начиная с него можно восстановить все состояния по массиву $s$. \n",
    "\n",
    "Осталось уточнить, как стартовать последовательный пересчет (чем заполнить первый столбец массива вероятностей):\n",
    "\n",
    "$$\\delta(k, 1) = p(k) p(x_1|t_1=k)$$\n",
    "\n",
    "В реализации рекомендуется перейти к логарифмам, т.к. произведение большого числа маленьких вероятностей может приводить к вычислительным ошибкам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Проверьте работу реализованного алгоритма на следующих модельных примерах, проинтерпретируйте результат.\n",
    "\n",
    "- 'he can stay'\n",
    "- 'a milk can'\n",
    "- 'i saw a dog'\n",
    "- 'an old saw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hmm = HMM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hmm.fit(X_train + X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'PRON', u'VERB', u'VERB']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.predict('he can stay'.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'DET', u'NOUN', u'VERB']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.predict('a milk can'.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'PRON', u'VERB', u'DET', u'NOUN']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.predict('i saw a dog'.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'DET', u'ADJ', u'VERB']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.predict('an old saw'.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Примените модель к отложенной выборке Брауновского корпуса и подсчитайте точность определения тегов (accuracy). Сделайте выводы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 1.3. Готовые POS-теггеры из NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "В прошлом пункте Вы реализовали свой POS-тегер на основе скрытой марковской модели. Теперь сравните его работу с готовыми средставми, доступными в библиотеке NLTK: http://www.nltk.org/api/nltk.tag.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Примерный набор кандидатов для сравнения:\n",
    "- Простейший теггер, который всем словам ставит в соответствие одну и ту же метку\n",
    "- Основанный на правилах RegexpTagger (правила можно поискать в Интернете или придумать самим)\n",
    "- N-граммные теггеры (разберитесь и поэкспериментируйте с параметром backoff)\n",
    "- Теггеры на основе графических моделей (можно взять только Stanford): \n",
    "    - HiddenMarkovModelTagger\n",
    "    - CRFTagger\n",
    "    - StanfordPOSTagger (потребуется .jar файл теггера и обученная модель (легко находятся в Интернете), чтобы подать на вход конструктору класса)\n",
    "- BrillTagger, основанный на трансформациях\n",
    "\n",
    "Если работа с какими-то модулями приводит к техническим проблемам, которые Вы не можете решить, это не страшно, модуль можно пропустить. Однако навык быстрого освоения документации / поиска моделей в гугле полезен.  Чем более полным и корректным будет сравнение, тем лучше.\n",
    "\n",
    "При проведении экспериментов обращайте внимание на следующие моменты (и отразите их в отчете):\n",
    "- Какой подход лежит в основе теггера\n",
    "- На каких данных он обучен (если Вы скачали готовую модель)\n",
    "- Сколько времени занимает обучение на brown корпусе (если обучаете сами)\n",
    "- Какая точность получается на контролькой выборке (метод evaluate())\n",
    "\n",
    "Сформируйте рекоммендиции о том, какую технологию Вы бы использовали, если встретитесь с задачей определения частей речи в будущем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag import DefaultTagger\n",
    "from nltk.tag import RegexpTagger\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.tag import BigramTagger\n",
    "from nltk.tag import TrigramTagger\n",
    "from nltk.tag import  HiddenMarkovModelTagger\n",
    "from nltk.tag import CRFTagger\n",
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "from nltk.tag import BrillTagger\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Выделение именованных сущностей (NER)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 2.1. Генерация признаков для CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Выделение именованных сущностей - другая распространенная задача разметки последовательности слов. Чаще всего она решается марковскими моделями максимальной энтропии (MEMM) или условными случайными полями (CRF). При этом основная сложность заключается в генерации  хороших признаков. \n",
    "\n",
    "В данном задании Вам требуется придумать и использовать множество признаков для обучения CRF из библиотеки CRFsuite. В этой библиотеке реализована linear-chain CRF с потенциалами двух типов (аналогично HMM):\n",
    "\n",
    "$$ \\psi_{mk}(t_{i-1}, t_{i}) = [t_{i-1} = m] \\, [t_{i} = k]; \\quad \\psi_{jk}(t_{i}, x_i) = [t_{i} = k] \\, f_j(x_i)$$\n",
    "\n",
    "\n",
    "Потенциалы первого типа назвают transition features, они зависят только от биграмм меток. Потенциалы второго типа -- label-observation (node-observation) featrues; они зависят от метки и признаков наблюдаемого слова (observation features). Несмотря на то, что в формуле явно участвует текущее слово $x_i$, подход остается полностью корректным, когда признаки зависят также от контекста слова (соседних слов). Это следствие того, что CRF является дискриминативной моделью, и наблюдаемые переменные $X$ не моделируются. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Указания к заданию:** \n",
    "- Загрузите из NLTK обучающие и тестовые датасеты для задачи выделения именованных сущеностей CoNLL 2002 shared task на английском, испанском и голландском языках в BIO-нотации (nltk.corpus.conll2002).\n",
    "- Для обучения CRF модели библиотеке необходимо передать последовательность наблюдаемых признаков $f_j(x_i)$ и меток $y_i$. Ниже приведен весь технический код, который позволит сконцентрироваться только на самом творческом этапе -- генерации признаков.\n",
    "- Оцените качество приведенного решения. \n",
    "- Ваша задача заключается в том, чтобы повысить его. Помимо генерации новых признаков, можно обратить внимание на параметры обучения, в частности, feature.minfreq позволяет отсеивать редкие признаки.  \n",
    "- При проверке задания будет оцениваться как достигнутое качество, так и разнообразие/оригинальность использованных признаков. Если вы попробовали какие-то признаки, но они не помогли, также включите их в отчет. \n",
    "- Если у Вас закончилась фантазия, почитайте обзоры и статьи по теме.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Let's define very simple example features.\n",
    "\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'postag=' + postag,\n",
    "        # your code here\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:postag=' + postag1,\n",
    "            # your code here\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    # your code here\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Let's prepare functions for more comfortable work with pycrfsuite.\n",
    "\n",
    "import pycrfsuite\n",
    "\n",
    "MODEL_NAME = 'model.crfsuite'\n",
    "\n",
    "def train(train):\n",
    "    X_train = [sent2features(s) for s in train]\n",
    "    y_train = [sent2labels(s) for s in train]\n",
    "\n",
    "    trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "    trainer.set_params({'c1': 1.0, 'c2': 1e-3, 'max_iterations': 50,\n",
    "                        'feature.possible_transitions': True})\n",
    "\n",
    "    for xseq, yseq in zip(X_train, y_train):\n",
    "        trainer.append(xseq, yseq)\n",
    "\n",
    "    trainer.train(MODEL_NAME)\n",
    "\n",
    "def evaluate(test):\n",
    "    X_test = [sent2features(s) for s in test]\n",
    "    y_test = [sent2labels(s) for s in test]\n",
    "\n",
    "    tagger = pycrfsuite.Tagger()\n",
    "    tagger.open(MODEL_NAME)\n",
    "\n",
    "    y_pred = [tagger.tag(x) for x in X_test]\n",
    "\n",
    "    true_counter, total_counter = 0.0, 0.0\n",
    "    for p, t in zip(y_pred, y_test):\n",
    "        assert len(p) == len(t)\n",
    "        total_counter += len(p)\n",
    "        true_counter += sum([str(i) == str(j) for i, j in zip(p, t)])\n",
    "    return true_counter / total_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 2.2. Stanford NER tagger\n",
    "\n",
    "Воспользуйтесь StanfordNERTagger для решения задачи NER на тех же тестовых данных, только для английского языка (обучать модель здесь не требуется). Приведите данные в соответствие нужному формату. Сравните результат с полученным выше. Настройка StanfordNERTagger производится аналогично настройке StanfordPOSTagger. В качестве готовой модели можно взять 'english.all.3class.distsim.crf.ser.gz'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
